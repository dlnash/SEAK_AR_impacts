{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa95c261-0095-455b-babc-acd6209ce4bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<dask.config.set at 0x1555517f19a0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## import libraries\n",
    "import os, sys\n",
    "import yaml\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import metpy.calc as mpcalc\n",
    "from metpy.units import units\n",
    "import dask\n",
    "from datetime import timedelta\n",
    "%matplotlib inline\n",
    "\n",
    "sys.path.append('../modules')\n",
    "import ar_funcs\n",
    "dask.config.set(**{'array.slicing.split_large_chunks': True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4d78ade-4b91-4aab-b542-3f8e27b4c7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = '/cw3e/mead/projects/cwp140/scratch/dnash/data/'      # project data -- read only\n",
    "path_to_out  = '../out/'       # output files (numerical results, intermediate datafiles) -- read & write\n",
    "path_to_figs = '../figs/'      # figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96cc7f58-a892-43b1-a3b8-3d86c42178e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filename_GEFSv12_reforecast(F):\n",
    "    ## this is the number of hours of lead time\n",
    "    ## for getting the correct filename\n",
    "    \n",
    "    # F = int((np.timedelta64(ndays, 'D')+np.timedelta64(nhours, 'h'))/np.timedelta64(1, 'h'))\n",
    "    ## the F-lead that the files are saved as\n",
    "    li = [3, 24, 27, 48, 51, 72, 75, 96, 99, 120, 123, 144, 147, 168, 171, 192, 195, 216, 219, 240]\n",
    "    \n",
    "    for idx in range(len(li)-1):\n",
    "        if li[idx] < F <= li[idx+1]:\n",
    "            pos1, pos2 = idx, idx+1\n",
    "\n",
    "    return li[pos1], li[pos2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9fb04d0a-cc24-41ad-a232-eb486951aef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "yr = 2000\n",
    "mon=2\n",
    "day=29\n",
    "center_date = '{0}-{1}-{2}'.format(yr, mon, day)\n",
    "center_date = pd.to_datetime(center_date)\n",
    "end_date = center_date + timedelta(days=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d62b7ce5-3792-4abc-a92c-4abe8fd3aedc",
   "metadata": {},
   "outputs": [
    {
     "ename": "DateParseError",
     "evalue": "day is out of range for month: 2001-2-29, at position 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32mparsing.pyx:681\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.parsing.dateutil_parse\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: day is out of range for month",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mDateParseError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:10\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/SEAK-impacts/lib/python3.12/site-packages/pandas/core/tools/datetimes.py:1146\u001b[0m, in \u001b[0;36mto_datetime\u001b[0;34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[0m\n\u001b[1;32m   1144\u001b[0m         result \u001b[38;5;241m=\u001b[39m convert_listlike(argc, \u001b[38;5;28mformat\u001b[39m)\n\u001b[1;32m   1145\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1146\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_listlike\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43marg\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1147\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg, \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, np\u001b[38;5;241m.\u001b[39mbool_):\n\u001b[1;32m   1148\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mbool\u001b[39m(result)  \u001b[38;5;66;03m# TODO: avoid this kludge.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/SEAK-impacts/lib/python3.12/site-packages/pandas/core/tools/datetimes.py:490\u001b[0m, in \u001b[0;36m_convert_listlike_datetimes\u001b[0;34m(arg, format, name, utc, unit, errors, dayfirst, yearfirst, exact)\u001b[0m\n\u001b[1;32m    487\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmixed\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    488\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _array_strptime_with_fallback(arg, name, utc, \u001b[38;5;28mformat\u001b[39m, exact, errors)\n\u001b[0;32m--> 490\u001b[0m result, tz_parsed \u001b[38;5;241m=\u001b[39m \u001b[43mobjects_to_datetime64ns\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m    \u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdayfirst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdayfirst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[43myearfirst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43myearfirst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m    \u001b[49m\u001b[43mutc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mutc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_object\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tz_parsed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    500\u001b[0m     \u001b[38;5;66;03m# We can take a shortcut since the datetime64 numpy array\u001b[39;00m\n\u001b[1;32m    501\u001b[0m     \u001b[38;5;66;03m# is in UTC\u001b[39;00m\n\u001b[1;32m    502\u001b[0m     dta \u001b[38;5;241m=\u001b[39m DatetimeArray(result, dtype\u001b[38;5;241m=\u001b[39mtz_to_dtype(tz_parsed))\n",
      "File \u001b[0;32m~/miniconda3/envs/SEAK-impacts/lib/python3.12/site-packages/pandas/core/arrays/datetimes.py:2346\u001b[0m, in \u001b[0;36mobjects_to_datetime64ns\u001b[0;34m(data, dayfirst, yearfirst, utc, errors, allow_object)\u001b[0m\n\u001b[1;32m   2343\u001b[0m \u001b[38;5;66;03m# if str-dtype, convert\u001b[39;00m\n\u001b[1;32m   2344\u001b[0m data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(data, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mobject_)\n\u001b[0;32m-> 2346\u001b[0m result, tz_parsed \u001b[38;5;241m=\u001b[39m \u001b[43mtslib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray_to_datetime\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2347\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2348\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mutc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mutc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdayfirst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdayfirst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2351\u001b[0m \u001b[43m    \u001b[49m\u001b[43myearfirst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43myearfirst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2352\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2354\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tz_parsed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2355\u001b[0m     \u001b[38;5;66;03m# We can take a shortcut since the datetime64 numpy array\u001b[39;00m\n\u001b[1;32m   2356\u001b[0m     \u001b[38;5;66;03m#  is in UTC\u001b[39;00m\n\u001b[1;32m   2357\u001b[0m     \u001b[38;5;66;03m# Return i8 values to denote unix timestamps\u001b[39;00m\n\u001b[1;32m   2358\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mi8\u001b[39m\u001b[38;5;124m\"\u001b[39m), tz_parsed\n",
      "File \u001b[0;32mtslib.pyx:403\u001b[0m, in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mtslib.pyx:552\u001b[0m, in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mtslib.pyx:517\u001b[0m, in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mconversion.pyx:546\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.conversion.convert_str_to_tsobject\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsing.pyx:331\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.parsing.parse_datetime_string\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsing.pyx:685\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.parsing.dateutil_parse\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mDateParseError\u001b[0m: day is out of range for month: 2001-2-29, at position 0"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "F = 72\n",
    "mon = 2\n",
    "day = 29\n",
    "\n",
    "## for each year between 2000 and 2019\n",
    "date_lst = []\n",
    "for i, yr in enumerate(range(2000, 2020)):\n",
    "    ## get 45 days before date\n",
    "    center_date = '{0}-{1}-{2}'.format(yr, mon, day)\n",
    "    center_date = pd.to_datetime(center_date)\n",
    "    start_date = center_date - timedelta(days=45)\n",
    "    \n",
    "    ## get 45 days after November 21\n",
    "    end_date = center_date + timedelta(days=45)\n",
    "\n",
    "    ## make a list of dates between start_date and end_date\n",
    "    dates = pd.date_range(start_date, end_date, freq='1D')\n",
    "    \n",
    "    date_lst.append(dates)\n",
    "    \n",
    "## concatenate all years together into single list    \n",
    "final_lst = np.concatenate(date_lst)\n",
    "print(start_date, end_date)\n",
    "\n",
    "## load all days from the new subset\n",
    "## create list of fnames\n",
    "fname_lst = []\n",
    "path_to_data = '/data/projects/Comet/cwp140/'\n",
    "path_to_data = '/cw3e/mead/projects/cwp140/scratch/dnash/data/'\n",
    "varname = 'ivt'\n",
    "\n",
    "## append filenames to a list\n",
    "print('Gathering filenames ...')\n",
    "for i, dt in enumerate(final_lst):\n",
    "    ts = pd.to_datetime(str(dt)) \n",
    "    d = ts.strftime(\"%Y%m%d\")\n",
    "    F1, F2 = get_filename_GEFSv12_reforecast(F)\n",
    "    fname = path_to_data + 'preprocessed/GEFSv12_reforecast/{0}/{1}_{0}_F{2}_F{3}.nc'.format(varname, d, F1, F2)\n",
    "    fname_lst.append(fname)\n",
    "\n",
    "### Read the dataset\n",
    "print('Reading the data ...')\n",
    "### Select the xx hr lead time step\n",
    "## this is the index value for selecting the timestep in the dataset\n",
    "idx = np.timedelta64(int(np.timedelta64(F, 'h')/np.timedelta64(1, 'ns')), 'ns')\n",
    "\n",
    "def preprocess(ds):\n",
    "    ds = ds.drop_vars([\"ivtu\", \"ivtv\"])\n",
    "    ds = ds.sel(step=idx) # select the 24 hr lead step\n",
    "    \n",
    "    return ds\n",
    "\n",
    "## use xr.open_mfdataset to read all the files within that ssn clim\n",
    "ds = xr.open_mfdataset(fname_lst, concat_dim=\"valid_time\", combine=\"nested\", engine='netcdf4', chunks={\"lat\": 100, \"lon\": 100}, preprocess=preprocess)\n",
    "\n",
    "print('Calculating quantiles...')\n",
    "## need to rechunk so time is a single chunk\n",
    "ds = ds.chunk(dict(valid_time=-1))\n",
    "\n",
    "# Percentile will be a set range of percentiles including <90th, then every 0.1 until 100th/MAX\n",
    "# I might add 75th-90th, and < 75th\n",
    "a = np.array([0, .75, .9])\n",
    "b = np.arange(.91, 1.001, 0.01)\n",
    "quantile_arr = np.concatenate((a, b), axis=0)\n",
    "\n",
    "## Calculate the percentiles\n",
    "ivt_mclimate = ds.quantile(quantile_arr, dim=['valid_time', 'number'], skipna=True)\n",
    "\n",
    "## add dayofyear and lead to coordinates\n",
    "ivt_mclimate = ivt_mclimate.assign_coords(step=F)\n",
    "ivt_mclimate = ivt_mclimate.expand_dims('step')\n",
    "period = pd.Period(\"2023-{0}-{1}\".format(mon, day), freq='H')\n",
    "ivt_mclimate = ivt_mclimate.assign_coords(dayofyear=period.day_of_year)\n",
    "ivt_mclimate = ivt_mclimate.expand_dims('dayofyear')\n",
    "ivt_mclimate\n",
    "\n",
    "# write to netCDF\n",
    "fname = os.path.join(path_to_data, 'preprocessed/GEFSv12_reforecast_mclimate_ivt_{0}{1}_{2}hr-lead.nc'.format(mon, day, F))\n",
    "ivt_mclimate.load().to_netcdf(path=fname, mode = 'w', format='NETCDF4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922ce3af-a397-4c63-b7e7-616f050f4c81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (SEAK-impacts)",
   "language": "python",
   "name": "seak-impacts"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

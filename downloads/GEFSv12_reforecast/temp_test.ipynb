{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "309124cb-3fb0-41ea-b52a-f62d01d1b7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "## import libraries\n",
    "import os, sys\n",
    "import yaml\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "path_to_repo = '/cw3e/mead/projects/cwp140/scratch/dnash/repos/SEAK_AR_impacts/'\n",
    "sys.path.append(path_to_repo+'modules')\n",
    "import GEFSv12_funcs as gefs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b06632f-96a8-4456-a16e-ff6d6f6f6fff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 8\n",
      "Loading u, v, and q data ....\n",
      "Loading surface pressure data ....\n",
      "Masking values below surface ....\n",
      "Calculating IVT ....\n",
      "Writing 20091226 to netCDF ....\n",
      "8 16\n",
      "Loading u, v, and q data ....\n",
      "Loading surface pressure data ....\n",
      "Masking values below surface ....\n",
      "Calculating IVT ....\n",
      "Writing 20091226 to netCDF ....\n",
      "16 24\n",
      "Loading u, v, and q data ....\n",
      "Loading surface pressure data ....\n",
      "Masking values below surface ....\n",
      "Calculating IVT ....\n",
      "Writing 20091226 to netCDF ....\n",
      "24 32\n",
      "Loading u, v, and q data ....\n",
      "Loading surface pressure data ....\n",
      "Masking values below surface ....\n",
      "Calculating IVT ....\n",
      "Writing 20091226 to netCDF ....\n",
      "32 40\n",
      "Loading u, v, and q data ....\n",
      "Loading surface pressure data ....\n",
      "Masking values below surface ....\n",
      "Calculating IVT ....\n",
      "Writing 20091226 to netCDF ....\n",
      "40 48\n",
      "Loading u, v, and q data ....\n",
      "Loading surface pressure data ....\n",
      "Masking values below surface ....\n",
      "Calculating IVT ....\n",
      "Writing 20091226 to netCDF ....\n",
      "48 56\n",
      "Loading u, v, and q data ....\n",
      "Loading surface pressure data ....\n",
      "Masking values below surface ....\n",
      "Calculating IVT ....\n",
      "Writing 20091226 to netCDF ....\n",
      "56 64\n",
      "Loading u, v, and q data ....\n",
      "Loading surface pressure data ....\n",
      "Masking values below surface ....\n",
      "Calculating IVT ....\n",
      "Writing 20091226 to netCDF ....\n",
      "64 72\n",
      "Loading u, v, and q data ....\n",
      "Loading surface pressure data ....\n",
      "Masking values below surface ....\n",
      "Calculating IVT ....\n",
      "Writing 20091226 to netCDF ....\n",
      "72 80\n",
      "Loading u, v, and q data ....\n",
      "Loading surface pressure data ....\n",
      "Masking values below surface ....\n",
      "Calculating IVT ....\n",
      "Writing 20091226 to netCDF ....\n",
      "CPU times: user 24min 59s, sys: 13min 28s, total: 38min 27s\n",
      "Wall time: 11min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "config_file = 'config_2.yaml' # this is the config file name\n",
    "job_info = 'job_1' # this is the job name\n",
    "\n",
    "for i, st in enumerate(range(0, 80, 8)):\n",
    "    print(st, st+8)\n",
    "    start = st\n",
    "    stop = st+8\n",
    "    path_to_data = '/cw3e/mead/projects/cwp140/scratch/dnash/data/'\n",
    "    \n",
    "    config = yaml.load(open(config_file), Loader=yaml.SafeLoader) # read the file\n",
    "    ddict = config[job_info] # pull the job info from the dict\n",
    "    \n",
    "    year = ddict['year']\n",
    "    date = ddict['date']\n",
    "    varname = 'ivt' ## can be 'ivt', 'freezing_level', or 'prec'\n",
    "    \n",
    "    print('Loading u, v, and q data ....')\n",
    "    varname_lst = ['ugrd', 'vgrd', 'spfh']\n",
    "    ds_lst = []\n",
    "    for i, varname in enumerate(varname_lst):\n",
    "        ds = gefs.read_and_regrid_prs_var(varname, date, year, start, stop)\n",
    "        ds_lst.append(ds)\n",
    "    \n",
    "    ## load in surface pressure\n",
    "    print('Loading surface pressure data ....')\n",
    "    ds_pres = gefs.read_sfc_var('pres', date, year, start, stop)\n",
    "    ds_lst.append(ds_pres)\n",
    "    \n",
    "    ds = xr.merge(ds_lst) # merge u, v, and q into single ds\n",
    "    ds = ds.sel(isobaricInhPa=slice(300, 1000))\n",
    "    ds = ds.reindex(isobaricInhPa=ds.isobaricInhPa[::-1])\n",
    "    \n",
    "    ## need to rechunk so lead time is smaller\n",
    "    # ds = ds.chunk({\"step\": 10})\n",
    "    \n",
    "    ## mask values below surface pressure\n",
    "    print('Masking values below surface ....')\n",
    "    varlst = ['q', 'u', 'v']\n",
    "    for i, varname in enumerate(varlst):\n",
    "        ds[varname] = ds[varname].where(ds[varname].isobaricInhPa < ds.sp/100., drop=False)\n",
    "    \n",
    "    ## integrate to calculate IVT\n",
    "    print('Calculating IVT ....')\n",
    "    ds_IVT = gefs.calc_IVT_manual(ds) # calculate IVT\n",
    "\n",
    "    # get info for saving file\n",
    "    start = ds_IVT.step.values[0].astype('timedelta64[h]')\n",
    "    stop = ds_IVT.step.values[-1].astype('timedelta64[h]')\n",
    "    start = int(start / np.timedelta64(1, 'h'))\n",
    "    stop = int(stop / np.timedelta64(1, 'h'))\n",
    "\n",
    "    ## save IVT data to netCDF file\n",
    "    print('Writing {0} to netCDF ....'.format(date))\n",
    "    out_fname = path_to_data + 'preprocessed/GEFSv12_reforecast/ivt/{0}_ivt_F{1}_F{2}.nc'.format(date, start, stop) \n",
    "    ds_IVT.load().to_netcdf(path=out_fname, mode = 'w', format='NETCDF4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ee543f73-4266-4191-b79e-f50e18b38950",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "import numpy as np\n",
    "import yaml\n",
    "from itertools import chain\n",
    "\n",
    "## for each year between 2000 and 2019\n",
    "date_lst = []\n",
    "for i, yr in enumerate(range(2000, 2020)):\n",
    "    ## get 55 days before November 21\n",
    "    center_date = '{0}-11-21'.format(yr)\n",
    "    center_date = pd.to_datetime(center_date)\n",
    "    start_date = center_date - timedelta(days=55)\n",
    "    \n",
    "    ## get 45 days after November 21\n",
    "    end_date = center_date + timedelta(days=45)\n",
    "\n",
    "    ## make a list of dates between start_date and end_date\n",
    "    dates = pd.date_range(start_date, end_date, freq='1D')\n",
    "    \n",
    "    date_lst.append(dates)\n",
    "    \n",
    "final_lst = np.concatenate(date_lst)\n",
    "\n",
    "jobcounter = 0\n",
    "filecounter = 0\n",
    "## loop through to create dictionary for each job\n",
    "d_lst = []\n",
    "dest_lst = []\n",
    "njob_lst = []\n",
    "for i, date in enumerate(final_lst):\n",
    "    jobcounter += 1\n",
    "    t = pd.to_datetime(str(date)) \n",
    "    yr = t.strftime(\"%Y\")\n",
    "    dt = t.strftime(\"%Y%m%d\")\n",
    "    d = {'job_{0}'.format(jobcounter):\n",
    "         {'year': yr,\n",
    "          'date': dt,\n",
    "          'ens': 'c00'\n",
    "          }}\n",
    "    d_lst.append(d)\n",
    "    \n",
    "    if (jobcounter == 999):\n",
    "        filecounter += 1\n",
    "        ## merge all the dictionaries to one\n",
    "        dest = dict(chain.from_iterable(map(dict.items, d_lst)))\n",
    "        njob_lst.append(len(d_lst))\n",
    "        ## write to .yaml file and close\n",
    "        file=open(\"config_{0}.yaml\".format(str(filecounter)),\"w\")\n",
    "        yaml.dump(dest,file, allow_unicode=True, default_flow_style=None)\n",
    "        file.close()\n",
    "        \n",
    "        ## reset jobcounter and d_lst\n",
    "        jobcounter = 0\n",
    "        d_lst = []\n",
    "        \n",
    "## now save the final config\n",
    "filecounter += 1\n",
    "## merge all the dictionaries to one\n",
    "dest = dict(chain.from_iterable(map(dict.items, d_lst)))\n",
    "njob_lst.append(len(d_lst))\n",
    "## write to .yaml file and close\n",
    "file=open(\"config_{0}.yaml\".format(str(filecounter)),\"w\")\n",
    "yaml.dump(dest,file, allow_unicode=True, default_flow_style=None)\n",
    "file.close()\n",
    "\n",
    "## create calls.txt for config_1(-8)\n",
    "\n",
    "for i, njobs in enumerate(njob_lst):\n",
    "    call_str_lst = []\n",
    "    for j, job in enumerate(range(1, njobs+1, 1)):\n",
    "        call_string = \"python getGEFSv12_batch.py config_{0}.yaml 'job_{1}'\".format(i+1, j+1)\n",
    "        call_str_lst.append(call_string)\n",
    "        \n",
    "    ## now write those lines to a text file\n",
    "    with open('calls_{0}.txt'.format(i+1), 'w',encoding='utf-8') as f:\n",
    "        for line in call_str_lst:\n",
    "            f.write(line)\n",
    "            f.write('\\n')\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92bf55f8-17f5-4771-82b4-2fab5f5bae09",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Filename:    getGEFSv12_batch.py\n",
    "Author:      Deanna Nash, dnash@ucsd.edu\n",
    "Description: Download GEFSv12 Reforecast data based on input configuration dictionary.\n",
    "\n",
    "\"\"\"\n",
    "import sys\n",
    "import yaml\n",
    "import subprocess\n",
    "\n",
    "### Imports config name from argument when submit\n",
    "yaml_doc = sys.argv[1]\n",
    "config_name = sys.argv[2]\n",
    "\n",
    "# import configuration file for season dictionary choice\n",
    "config = yaml.load(open(yaml_doc), Loader=yaml.SafeLoader)\n",
    "ddict = config[config_name]\n",
    "\n",
    "year = ddict['year']\n",
    "date = ddict['date']\n",
    "ens = ddict['ens']\n",
    "varname = 'ivt' ## can be 'ivt', 'freezing_level', or 'prec'\n",
    "\n",
    "## run download_GEFSv12_reforecast.sh to download data \n",
    "bash_script = \"download_GEFSv12_reforecast.sh\"\n",
    "print(subprocess.run([bash_script, year, date, ens, varname]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:SEAK-impacts]",
   "language": "python",
   "name": "conda-env-SEAK-impacts-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

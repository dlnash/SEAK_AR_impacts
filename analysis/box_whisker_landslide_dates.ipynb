{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87f7ed3e-efab-4dcc-9ce1-2b66bdc4721d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Python modules\n",
    "import os, sys\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "\n",
    "# plot styles/formatting\n",
    "import seaborn as sns\n",
    "import cmocean.cm as cmo\n",
    "import cmocean\n",
    "\n",
    "# matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import AxesGrid\n",
    "import matplotlib.ticker as mticker\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from matplotlib.colorbar import Colorbar # different way to handle colorbar\n",
    "from matplotlib.colorbar import ColorbarBase\n",
    "import matplotlib.colors as mcolors\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "from mpl_toolkits.axes_grid1.axes_divider import make_axes_locatable\n",
    "from matplotlib.projections import get_projection_class\n",
    "\n",
    "sys.path.append('../modules')\n",
    "from timeseries import select_months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "390e0e6c-af50-48a6-82d5-07318038ece6",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = '/expanse/nfs/cw3e/cwp140/'\n",
    "path_to_out  = '../out/'       # output files (numerical results, intermediate datafiles) -- read & write\n",
    "path_to_figs = '../figs/'      # figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "818ff41e-43ba-43ba-bb08-f2e17f7d98dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>impact_date</th>\n",
       "      <th>init_date</th>\n",
       "      <th>model_name</th>\n",
       "      <th>F</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2002-07-09</td>\n",
       "      <td>2002-07-08</td>\n",
       "      <td>GEFSv12_reforecast</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2002-07-09</td>\n",
       "      <td>2002-07-07</td>\n",
       "      <td>GEFSv12_reforecast</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2002-07-09</td>\n",
       "      <td>2002-07-06</td>\n",
       "      <td>GEFSv12_reforecast</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2002-07-09</td>\n",
       "      <td>2002-07-05</td>\n",
       "      <td>GEFSv12_reforecast</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2002-07-09</td>\n",
       "      <td>2002-07-04</td>\n",
       "      <td>GEFSv12_reforecast</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4797</th>\n",
       "      <td>2024-09-16</td>\n",
       "      <td>2024-09-13</td>\n",
       "      <td>GEFS_archive</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4798</th>\n",
       "      <td>2024-09-16</td>\n",
       "      <td>2024-09-12</td>\n",
       "      <td>GEFS_archive</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4799</th>\n",
       "      <td>2024-09-16</td>\n",
       "      <td>2024-09-11</td>\n",
       "      <td>GEFS_archive</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4800</th>\n",
       "      <td>2024-09-16</td>\n",
       "      <td>2024-09-10</td>\n",
       "      <td>GEFS_archive</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4801</th>\n",
       "      <td>2024-09-16</td>\n",
       "      <td>2024-09-09</td>\n",
       "      <td>GEFS_archive</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4802 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     impact_date  init_date          model_name    F\n",
       "0     2002-07-09 2002-07-08  GEFSv12_reforecast   24\n",
       "1     2002-07-09 2002-07-07  GEFSv12_reforecast   48\n",
       "2     2002-07-09 2002-07-06  GEFSv12_reforecast   72\n",
       "3     2002-07-09 2002-07-05  GEFSv12_reforecast   96\n",
       "4     2002-07-09 2002-07-04  GEFSv12_reforecast  120\n",
       "...          ...        ...                 ...  ...\n",
       "4797  2024-09-16 2024-09-13        GEFS_archive   72\n",
       "4798  2024-09-16 2024-09-12        GEFS_archive   96\n",
       "4799  2024-09-16 2024-09-11        GEFS_archive  120\n",
       "4800  2024-09-16 2024-09-10        GEFS_archive  144\n",
       "4801  2024-09-16 2024-09-09        GEFS_archive  168\n",
       "\n",
       "[4802 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## read unique landslide dates\n",
    "df = pd.read_csv('../out/landslide_dates.csv')\n",
    "df = df.set_index(pd.to_datetime(df['init_date'], format='%Y%m%d'))\n",
    "final_dates_lst = df.index\n",
    "\n",
    "date_lst = []\n",
    "impact_date_lst = []\n",
    "model_lst = []\n",
    "F_lst = []\n",
    "for i, date in enumerate(final_dates_lst):\n",
    "    ## skip 2 events - 20200227, 20200817\n",
    "    ## the data from GEFS was too hard to download for these dates\n",
    "    if (date.strftime(\"%Y%m%d\") == '20200227') | (date.strftime(\"%Y%m%d\") == '20200817'):\n",
    "        pass\n",
    "    else:\n",
    "        for j, init_lead in enumerate(np.arange(1, 8)):\n",
    "            F_lst.append(init_lead*24) # lead in hours\n",
    "            init_date = date - pd.to_timedelta(init_lead, unit='D')\n",
    "            date_lst.append(init_date)\n",
    "            impact_date_lst.append(date)\n",
    "            \n",
    "            if init_date.year < 2020:\n",
    "                model_name = 'GEFSv12_reforecast'\n",
    "            else:\n",
    "                model_name = 'GEFS_archive'\n",
    "    \n",
    "            model_lst.append(model_name)\n",
    "\n",
    "d = {'impact_date': impact_date_lst, 'init_date': date_lst, 'model_name': model_lst, 'F': F_lst}\n",
    "df = pd.DataFrame(d)\n",
    "\n",
    "## cut the df so it takes out init dates before 2000-01-01\n",
    "idx = (df['init_date'] >= '2000-01-01')\n",
    "df = df.loc[idx]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fec02374-56c6-496b-af4b-a1ea494aa60a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m QPF_lst \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      5\u001b[0m AR_index_lst \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index, row \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdf\u001b[49m\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;66;03m## read csv files from landslide dates\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     model_name \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_name\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      9\u001b[0m     F \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mF\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "IVT_lst = []\n",
    "Z0_lst = []\n",
    "UV_lst = []\n",
    "QPF_lst = []\n",
    "AR_index_lst = []\n",
    "for index, row in df.iterrows():\n",
    "    ## read csv files from landslide dates\n",
    "    model_name = row['model_name']\n",
    "    F = row['F']\n",
    "    \n",
    "    fdate = row['init_date'].strftime(\"%Y%m%d\")\n",
    "    impact_date = row['impact_date'].strftime(\"%Y-%m-%d\")\n",
    "    try:\n",
    "        ## for each row, open the file using the init date\n",
    "        fname = '/expanse/nfs/cw3e/cwp140/csv_non-landslide_historical/mclimate_init{0}.csv'.format(fdate)\n",
    "        test = pd.read_csv(fname)\n",
    "        test[\"valid_time\"] = row['init_date'] + pd.to_timedelta((test.index + 1) * 6, unit=\"h\")\n",
    "        test = test.set_index(pd.to_datetime(test['valid_time']))\n",
    "        ## then subset to impact date\n",
    "        subset = test.loc[impact_date]\n",
    "        \n",
    "        ## pull the maximum values for each var\n",
    "        IVT_lst.append(subset['IVT'].max())\n",
    "        Z0_lst.append(subset['Freezing Level'].max())\n",
    "        UV_lst.append(subset['UV'].max())\n",
    "        QPF_lst.append(subset['QPF'].max())\n",
    "        AR_index_lst.append(subset['AR_index'].max())\n",
    "    except FileNotFoundError:\n",
    "        print('Skipping {0}, data not available...'.format(fdate))\n",
    "        ## set vals to nan\n",
    "        IVT_lst.append(np.nan)\n",
    "        Z0_lst.append(np.nan)\n",
    "        UV_lst.append(np.nan)\n",
    "        QPF_lst.append(np.nan)\n",
    "        AR_index_lst.append(np.nan)\n",
    "        \n",
    "\n",
    "df['IVT'] = IVT_lst\n",
    "df['Z0'] = Z0_lst\n",
    "df['UV'] = UV_lst\n",
    "df['QPF'] = QPF_lst\n",
    "df['AR_index'] = AR_index_lst\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e12ebd8-ae2a-4c7d-bd18-dbb53fa85b5d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 14\u001b[0m\n\u001b[1;32m      1\u001b[0m ssn \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# ## read csv\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# fname = path_to_out + 'box_whisker_2000-2019.csv'\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# df1 = pd.read_csv(fname)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# df['Z0'] = df['Z0']*100\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# df['UV'] = df['UV']*100\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241m.\u001b[39mset_index(pd\u001b[38;5;241m.\u001b[39mto_datetime(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimpact_date\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ssn \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDJF\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     16\u001b[0m     df \u001b[38;5;241m=\u001b[39m select_months(df, \u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "ssn = 'all'\n",
    "# ## read csv\n",
    "# fname = path_to_out + 'box_whisker_2000-2019.csv'\n",
    "# df1 = pd.read_csv(fname)\n",
    "\n",
    "# fname = path_to_out + 'box_whisker_2020-2024.csv'\n",
    "# df2 = pd.read_csv(fname)\n",
    "\n",
    "# df = pd.concat([df1, df2])\n",
    "# df['IVT'] = df['IVT']*100\n",
    "# df['Z0'] = df['Z0']*100\n",
    "# df['UV'] = df['UV']*100\n",
    "\n",
    "df = df.set_index(pd.to_datetime(df['impact_date']))\n",
    "if ssn == 'DJF':\n",
    "    df = select_months(df, 12, 2)\n",
    "elif ssn == 'cool-season':\n",
    "    df = select_months(df, 9, 2)\n",
    "else:\n",
    "    df = df\n",
    "df\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9719c1eb-e7ff-498c-ba09-33499350f5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "F_lst = np.arange(24, 168+24, 24)\n",
    "varlst = ['IVT', 'Z0', 'UV', 'QPF', 'AR_index']\n",
    "for j, F in enumerate(F_lst):\n",
    "    print('F = {0}'.format(F))\n",
    "    idx = (df.F == F)\n",
    "    tmp = df.loc[idx]\n",
    "    tmp = tmp.drop(columns=[\"impact_date\", \"init_date\", \"F\"])\n",
    "    print(tmp.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f0683c-2486-4d8e-934e-64497bbf5982",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create figure\n",
    "fig = plt.figure(figsize=(8.5, 11))\n",
    "fig.dpi = 300\n",
    "fname = path_to_figs + 'box_whisker_{0}'.format(ssn)\n",
    "fmt = 'png'\n",
    "\n",
    "nrows = 3\n",
    "ncols = 2\n",
    "\n",
    "## Use gridspec to set up a plot with a series of subplots that is\n",
    "## n-rows by n-columns\n",
    "gs = GridSpec(nrows, ncols, height_ratios=[1, 1, 1], width_ratios = [1, 1], wspace=0.2, hspace=0.2)\n",
    "## use gs[rows index, columns index] to access grids\n",
    "\n",
    "#######################\n",
    "### BOX AND WHISKER ###\n",
    "#######################\n",
    "varname_lst = ['IVT', 'Z0', 'UV', 'QPF', 'AR_index']\n",
    "color_lst = ['#54B36D', '#FC5F3F', '#9956AD', '#2171b5', '#DF65B0']\n",
    "row_lst = [0, 0, 1, 1, 2]\n",
    "col_lst = [0, 1, 0, 1, 0]\n",
    "for i, varname in enumerate(varname_lst):\n",
    "    ax = fig.add_subplot(gs[row_lst[i], col_lst[i]])\n",
    "    PROPS = {'boxprops':{'facecolor':color_lst[i], 'edgecolor':'k'},\n",
    "             'medianprops':{\"color\": \"k\"},\n",
    "             'whiskerprops':{\"color\": \"k\"},\n",
    "             'capprops':{\"color\": \"k\"},\n",
    "             'flierprops':{\"marker\": \"x\"},\n",
    "             'meanprops':{'c':'k', 'lw':1},\n",
    "             'bootstrap': 5000}\n",
    "    \n",
    "    bplot = sns.boxplot(y=varname, x=\"F\", data=df, \n",
    "                        whis=[0, 100],\n",
    "                    order=np.arange(24, 8*24, 24),\n",
    "                    meanline=True, showmeans=True, \n",
    "                    notch=False, showcaps=True,\n",
    "                    linewidth=0.75,\n",
    "                    **PROPS)\n",
    "    \n",
    "    #  set the ticks first\n",
    "    if varname == 'AR_index':\n",
    "        plt.ylim(-1., 6)\n",
    "        bplot.set_yticks(np.arange(0., 6, 1))\n",
    "    else:\n",
    "        plt.ylim(-1., 101)\n",
    "        bplot.set_yticks(np.arange(0., 101, 10))\n",
    "    ax.minorticks_on()\n",
    "    ax.tick_params(axis='y', which='minor', bottom=True)\n",
    "    ax.tick_params(axis='y', which='major')\n",
    "    \n",
    "        \n",
    "    # ax.set_title('(a)', loc='left')\n",
    "    # ax.annotate(plt_lbl[i], (5, 207), xycoords='axes points', fontsize=12.,\n",
    "    #         backgroundcolor='white', zorder=100)\n",
    "    if i <= 3:\n",
    "        ax.set_ylabel('{0} percentile rank (xth)'.format(varname))\n",
    "    else:\n",
    "        ax.set_ylabel('AR Impact Index')\n",
    "    ax.set_xlabel('Lead (hours)')\n",
    "\n",
    "\n",
    "fig.savefig('%s.%s' %(fname, fmt), bbox_inches='tight', dpi=fig.dpi, transparent=True)\n",
    "\n",
    "# Show\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2d070e-7fd5-4f2d-abac-1430e7f5f7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thus, if we have this weird \"flipped\" appearance in the notched box plots,\n",
    "# it simply means that the 1st quartile has a lower value than the confidence of the mean and \n",
    "# vice versa for the 3rd quartile. \n",
    "# Although it looks ugly, it's actually useful information about the (un)confidence of the median."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077662fe-982c-4676-8798-ebf6b9a5e906",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_fraction_percentiles(df, varname, F, perc_rank):\n",
    "    idx = df['F'] == F\n",
    "    denom = len(df.loc[idx]) # how many impact dates with lead time\n",
    "    \n",
    "    idx = (df[varname] == perc_rank) & (df['F'] == F)\n",
    "    numer = len(df.loc[idx]) # how many impact dates with lead time that have the percentile rank value\n",
    "    \n",
    "    return (numer/denom)*100\n",
    "data_lst = []\n",
    "varlst = ['IVT', 'Z0', 'UV', 'AR_index']\n",
    "for i, varname in enumerate(varlst):\n",
    "    if varname == 'AR_index':\n",
    "        perc_rank_lst = [0, 1, 2, 3, 4, 5]\n",
    "    else:\n",
    "        perc_rank_lst = [0., 75., 90., 94., 95., 96., 97., 98., 99., 100.]\n",
    "\n",
    "    F_lst = np.arange(24, 168+24, 24)\n",
    "    for j, perc_rank in enumerate(perc_rank_lst):\n",
    "        for k, F in enumerate(F_lst):\n",
    "            frac = calc_fraction_percentiles(df, varname, F, perc_rank)\n",
    "            data = (varname, perc_rank, F, frac)\n",
    "            data_lst.append(data)\n",
    "\n",
    "# create DataFrame using data\n",
    "df2 = pd.DataFrame(data_lst, columns =['Variable', 'Percentile Rank', 'F', 'Fraction'])\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0060233a-3ab4-4816-b023-3b2e2028e6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create figure\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "fig.dpi = 300\n",
    "fname = path_to_figs + 'heatmaps_{0}'.format(ssn)\n",
    "fmt = 'png'\n",
    "\n",
    "nrows = 2\n",
    "ncols = 2\n",
    "\n",
    "## Use gridspec to set up a plot with a series of subplots that is\n",
    "## n-rows by n-columns\n",
    "gs = GridSpec(nrows, ncols, height_ratios=[1, 1], width_ratios = [1, 1], wspace=0.3, hspace=0.2)\n",
    "## use gs[rows index, columns index] to access grids\n",
    "\n",
    "#######################\n",
    "### BOX AND WHISKER ###\n",
    "#######################\n",
    "varname_lst = ['IVT', 'Z0', 'UV', 'AR_index']\n",
    "title_lst = ['(a) IVT', '(b) Freezing Level', '(c) 1000-hPa wind', '(d) AR Impact Index']\n",
    "row_idx = [0, 0, 1, 1]\n",
    "col_idx = [0, 1, 0, 1]\n",
    "for i, varname in enumerate(varname_lst):\n",
    "    ax = fig.add_subplot(gs[row_idx[i], col_idx[i]])\n",
    "\n",
    "    tmp = df2.loc[df2['Variable'] == varname].pivot(index=\"Percentile Rank\", columns=\"F\", values=\"Fraction\")\n",
    "    if varname == 'AR_index':\n",
    "        tck_lbly = [0, 1, 2, 3, 4, 5]\n",
    "    else:\n",
    "        tck_lbly = ['< 75th', '75th', '90th', '94th', '95th', '96th', '97th', '98th', '99th', 'MAX']\n",
    "    g = sns.heatmap(tmp, annot=True, fmt=\".0f\", cmap=\"crest\", cbar=False, yticklabels=tck_lbly, ax=ax)\n",
    "    g.invert_yaxis()\n",
    "\n",
    "    ax.set_title(title_lst[i], loc='left')\n",
    "\n",
    "fig.savefig('%s.%s' %(fname, fmt), bbox_inches='tight', dpi=fig.dpi, transparent=True)\n",
    "\n",
    "# Show\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13735668-c782-472a-afb1-77ceaeddacbb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:SEAK-impacts]",
   "language": "python",
   "name": "conda-env-SEAK-impacts-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f7ed3e-efab-4dcc-9ce1-2b66bdc4721d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Python modules\n",
    "import os, sys\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "\n",
    "# plot styles/formatting\n",
    "import seaborn as sns\n",
    "import cmocean.cm as cmo\n",
    "import cmocean\n",
    "\n",
    "# matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import AxesGrid\n",
    "import matplotlib.ticker as mticker\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from matplotlib.colorbar import Colorbar # different way to handle colorbar\n",
    "from matplotlib.colorbar import ColorbarBase\n",
    "import matplotlib.colors as mcolors\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "from mpl_toolkits.axes_grid1.axes_divider import make_axes_locatable\n",
    "from matplotlib.projections import get_projection_class\n",
    "\n",
    "sys.path.append('../modules')\n",
    "from timeseries import select_months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390e0e6c-af50-48a6-82d5-07318038ece6",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = '/expanse/nfs/cw3e/cwp140/'\n",
    "path_to_out  = '../out/'       # output files (numerical results, intermediate datafiles) -- read & write\n",
    "path_to_figs = '../figs/'      # figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72cec767-528c-4d75-9ad9-22c83a91e6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## read unique landslide dates\n",
    "df = pd.read_csv(path_to_out + 'landslide_dates.csv')\n",
    "\n",
    "IVT_lst = []\n",
    "Z0_lst = []\n",
    "UV_lst = []\n",
    "AR_index_lst = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    ## read csv files from landslide dates\n",
    "    fdate = row['init_date']\n",
    "    impact_date = row['impact_date']\n",
    "    model_name = row['model_name']\n",
    "    F = row['F']\n",
    "    fname = '/expanse/nfs/cw3e/cwp140/images_historical/{1}/mclimate_init{0}.csv'.format(fdate, impact_date)\n",
    "    test = pd.read_csv(fname)\n",
    "    F_lst = np.arange(6, (len(test)*6)+6, 6)\n",
    "    test['F'] = F_lst\n",
    "    \n",
    "    idx = (test['F'] >= F) & (test['F'] < F+24)\n",
    "    subset = test.loc[idx]\n",
    "    \n",
    "    ## pull the maximum values for each var\n",
    "    IVT_lst.append(subset['IVT'].max())\n",
    "    Z0_lst.append(subset['Freezing Level'].max())\n",
    "    UV_lst.append(subset['UV'].max())\n",
    "    AR_index_lst.append(subset['AR_index'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d62d5a-ebf7-4469-806f-fcb2f0f564f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['IVT'] = IVT_lst\n",
    "df['Z0'] = Z0_lst\n",
    "df['UV'] = UV_lst\n",
    "df['AR_index'] = AR_index_lst\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e12ebd8-ae2a-4c7d-bd18-dbb53fa85b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ssn = 'cool-season'\n",
    "# ## read csv\n",
    "# fname = path_to_out + 'box_whisker_2000-2019.csv'\n",
    "# df1 = pd.read_csv(fname)\n",
    "\n",
    "# fname = path_to_out + 'box_whisker_2020-2024.csv'\n",
    "# df2 = pd.read_csv(fname)\n",
    "\n",
    "# df = pd.concat([df1, df2])\n",
    "# df['IVT'] = df['IVT']*100\n",
    "# df['Z0'] = df['Z0']*100\n",
    "# df['UV'] = df['UV']*100\n",
    "\n",
    "df = df.set_index(pd.to_datetime(df['impact_date']))\n",
    "if ssn == 'DJF':\n",
    "    df = select_months(df, 12, 2)\n",
    "elif ssn == 'cool-season':\n",
    "    df = select_months(df, 9, 2)\n",
    "else:\n",
    "    df = df\n",
    "df\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9719c1eb-e7ff-498c-ba09-33499350f5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = (df.F == 48)\n",
    "tmp = df.loc[idx]\n",
    "tmp.Z0.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f0683c-2486-4d8e-934e-64497bbf5982",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create figure\n",
    "fig = plt.figure(figsize=(11, 13.5))\n",
    "fig.dpi = 300\n",
    "fname = path_to_figs + 'box_whisker_{0}'.format(ssn)\n",
    "fmt = 'png'\n",
    "\n",
    "nrows = 4\n",
    "ncols = 1\n",
    "\n",
    "## Use gridspec to set up a plot with a series of subplots that is\n",
    "## n-rows by n-columns\n",
    "gs = GridSpec(nrows, ncols, height_ratios=[1, 1, 1, 1], width_ratios = [1], wspace=0.2, hspace=0.2)\n",
    "## use gs[rows index, columns index] to access grids\n",
    "\n",
    "#######################\n",
    "### BOX AND WHISKER ###\n",
    "#######################\n",
    "varname_lst = ['IVT', 'Z0', 'UV', 'AR_index']\n",
    "color_lst = ['#54B36D', '#FC5F3F', '#9956AD', '#DF65B0']\n",
    "for i, varname in enumerate(varname_lst):\n",
    "    ax = fig.add_subplot(gs[i, 0])\n",
    "    PROPS = {'boxprops':{'facecolor':color_lst[i], 'edgecolor':'k'},\n",
    "             'medianprops':{\"color\": \"k\"},\n",
    "             'whiskerprops':{\"color\": \"k\"},\n",
    "             'capprops':{\"color\": \"k\"},\n",
    "             'flierprops':{\"marker\": \"x\"},\n",
    "             'meanprops':{'c':'k', 'lw':1},\n",
    "             'bootstrap': 5000}\n",
    "    \n",
    "    bplot = sns.boxplot(y=varname, x=\"F\", data=df, \n",
    "                        whis=[0, 100],\n",
    "                    order=np.arange(24, 8*24, 24),\n",
    "                    meanline=True, showmeans=True, \n",
    "                    notch=False, showcaps=True,\n",
    "                    linewidth=0.75,\n",
    "                    **PROPS)\n",
    "    \n",
    "    #  set the ticks first\n",
    "    if varname == 'AR_index':\n",
    "        plt.ylim(-1., 6)\n",
    "        bplot.set_yticks(np.arange(0., 5, 1))\n",
    "    else:\n",
    "        plt.ylim(-1., 101)\n",
    "        bplot.set_yticks(np.arange(0., 101, 10))\n",
    "    ax.minorticks_on()\n",
    "    ax.tick_params(axis='y', which='minor', bottom=True)\n",
    "    ax.tick_params(axis='y', which='major')\n",
    "    \n",
    "        \n",
    "    # ax.set_title('(a)', loc='left')\n",
    "    # ax.annotate(plt_lbl[i], (5, 207), xycoords='axes points', fontsize=12.,\n",
    "    #         backgroundcolor='white', zorder=100)\n",
    "    \n",
    "    ax.set_ylabel('{0} percentile rank (xth)'.format(varname))\n",
    "    ax.set_xlabel('Lead (hours)')\n",
    "\n",
    "\n",
    "fig.savefig('%s.%s' %(fname, fmt), bbox_inches='tight', dpi=fig.dpi, transparent=True)\n",
    "\n",
    "# Show\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2d070e-7fd5-4f2d-abac-1430e7f5f7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thus, if we have this weird \"flipped\" appearance in the notched box plots,\n",
    "# it simply means that the 1st quartile has a lower value than the confidence of the mean and \n",
    "# vice versa for the 3rd quartile. \n",
    "# Although it looks ugly, it's actually useful information about the (un)confidence of the median."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077662fe-982c-4676-8798-ebf6b9a5e906",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_fraction_percentiles(df, varname, F, perc_rank):\n",
    "    idx = df['F'] == F\n",
    "    denom = len(df.loc[idx]) # how many impact dates with lead time\n",
    "    \n",
    "    idx = (df[varname] == perc_rank) & (df['F'] == F)\n",
    "    numer = len(df.loc[idx]) # how many impact dates with lead time that have the percentile rank value\n",
    "    \n",
    "    return (numer/denom)*100\n",
    "data_lst = []\n",
    "varlst = ['IVT', 'Z0', 'UV', 'AR_index']\n",
    "for i, varname in enumerate(varlst):\n",
    "    if varname == 'AR_index':\n",
    "        perc_rank_lst = [0, 1, 2, 3, 4, 5]\n",
    "    else:\n",
    "        perc_rank_lst = [0., 75., 90., 94., 95., 96., 97., 98., 99., 100.]\n",
    "\n",
    "    F_lst = np.arange(24, 168+24, 24)\n",
    "    for j, perc_rank in enumerate(perc_rank_lst):\n",
    "        for k, F in enumerate(F_lst):\n",
    "            frac = calc_fraction_percentiles(df, varname, F, perc_rank)\n",
    "            data = (varname, perc_rank, F, frac)\n",
    "            data_lst.append(data)\n",
    "\n",
    "# create DataFrame using data\n",
    "df2 = pd.DataFrame(data_lst, columns =['Variable', 'Percentile Rank', 'F', 'Fraction'])\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0060233a-3ab4-4816-b023-3b2e2028e6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create figure\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "fig.dpi = 300\n",
    "fname = path_to_figs + 'heatmaps_{0}'.format(ssn)\n",
    "fmt = 'png'\n",
    "\n",
    "nrows = 2\n",
    "ncols = 2\n",
    "\n",
    "## Use gridspec to set up a plot with a series of subplots that is\n",
    "## n-rows by n-columns\n",
    "gs = GridSpec(nrows, ncols, height_ratios=[1, 1], width_ratios = [1, 1], wspace=0.3, hspace=0.2)\n",
    "## use gs[rows index, columns index] to access grids\n",
    "\n",
    "#######################\n",
    "### BOX AND WHISKER ###\n",
    "#######################\n",
    "varname_lst = ['IVT', 'Z0', 'UV', 'AR_index']\n",
    "title_lst = ['(a) IVT', '(b) Freezing Level', '(c) 1000-hPa wind', '(d) AR Impact Index']\n",
    "row_idx = [0, 0, 1, 1]\n",
    "col_idx = [0, 1, 0, 1]\n",
    "for i, varname in enumerate(varname_lst):\n",
    "    ax = fig.add_subplot(gs[row_idx[i], col_idx[i]])\n",
    "\n",
    "    tmp = df2.loc[df2['Variable'] == varname].pivot(index=\"Percentile Rank\", columns=\"F\", values=\"Fraction\")\n",
    "    if varname == 'AR_index':\n",
    "        tck_lbly = [0, 1, 2, 3, 4, 5]\n",
    "    else:\n",
    "        tck_lbly = ['< 75th', '75th', '90th', '94th', '95th', '96th', '97th', '98th', '99th', 'MAX']\n",
    "    g = sns.heatmap(tmp, annot=True, fmt=\".0f\", cmap=\"crest\", cbar=False, yticklabels=tck_lbly, ax=ax)\n",
    "    g.invert_yaxis()\n",
    "\n",
    "    ax.set_title(title_lst[i], loc='left')\n",
    "\n",
    "fig.savefig('%s.%s' %(fname, fmt), bbox_inches='tight', dpi=fig.dpi, transparent=True)\n",
    "\n",
    "# Show\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13735668-c782-472a-afb1-77ceaeddacbb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (SEAK-impacts)",
   "language": "python",
   "name": "seak-impacts"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70f9c099-939a-483f-842c-bc988837ec54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR 1: PROJ: proj_create_from_database: Open of /home/dnash/miniconda3/envs/SEAK-impacts/share/proj failed\n"
     ]
    }
   ],
   "source": [
    "## import libraries\n",
    "import os, sys\n",
    "import yaml\n",
    "import re\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta\n",
    "%matplotlib inline\n",
    "from datetime import timedelta\n",
    "\n",
    "# plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from matplotlib.colorbar import Colorbar # different way to handle colorbar\n",
    "import textwrap\n",
    "import cmocean.cm as cmo\n",
    "\n",
    "# import personal modules\n",
    "sys.path.append('../modules')\n",
    "import custom_cmaps as ccmap\n",
    "from plotter import draw_basemap\n",
    "import ar_funcs\n",
    "import mclimate_funcs as mclim_func\n",
    "# dask.config.set(**{'array.slicing.split_large_chunks': True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "004036dc-0919-4d58-a884-81c60b59759d",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = '/expanse/nfs/cw3e/cwp140/'      # project data -- read only\n",
    "path_to_out  = '../out/'       # output files (numerical results, intermediate datafiles) -- read & write\n",
    "path_to_figs = '../figs/'      # figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8d30b8f-a919-4560-8627-6b2df510c403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 0 0\n"
     ]
    }
   ],
   "source": [
    "## get list of impact dates broken down by subregion\n",
    "df = ar_funcs.clean_impact_data(start_date = '2000-01-01', end_date = '2019-08-31')\n",
    "\n",
    "## Group together\n",
    "group_name = 'Northeast Gulf Coast'\n",
    "\n",
    "if group_name == 'Northeast Gulf Coast':\n",
    "    zone = \"northern_coastal\"\n",
    "    idx = (df['Location'] == 'PAYA')\n",
    "elif group_name == 'Central East Gulf Coast':\n",
    "    zone = \"central_coastal\"\n",
    "    idx = (df['Location'] == 'PASI')\n",
    "elif group_name == 'Southeast Gulf Coast':\n",
    "    zone = \"southern_coastal\"\n",
    "    idx = (df['Location'] == 'PAKW')\n",
    "elif group_name == 'Northern Inner Channels':\n",
    "    zone = \"northern_inner_channel\"\n",
    "    idx = (df['Location'] == 'PAHN') | (df['Location'] == 'COOPHCSA2') | (df['Location'] == 'PAGY')\n",
    "elif group_name == 'Central Inner Channels':\n",
    "    zone = \"central_inner_channel\"\n",
    "    idx = (df['Location'] == 'PAGS') | (df['Location'] == 'PAJN') | (df['Location'] == 'HONA2') | (df['Location'] == 'PAPG') | (df['Location'] == 'PAWG')\n",
    "    # 46 23 1\n",
    "elif group_name == 'Southern Inner Channels':\n",
    "    zone = \"southern_inner_channel\"\n",
    "    idx = (df['Location'] == 'PAKT') | (df['Location'] == 'KTNA2')\n",
    "\n",
    "df = df.loc[idx]\n",
    "\n",
    "idx = (df['Impact Level'] >=4)\n",
    "dates_high = pd.to_datetime(df.loc[idx].index.values).unique()\n",
    "\n",
    "idx = (df['Impact Level'] >1) & (df['Impact Level'] <4)\n",
    "dates_medium = pd.to_datetime(df.loc[idx].index.values).unique()\n",
    "\n",
    "idx = (df['Impact Level'] <=1)\n",
    "dates_low = pd.to_datetime(df.loc[idx].index.values).unique()\n",
    "\n",
    "dates_lst = [dates_low, dates_medium, dates_high]\n",
    "print(len(dates_low), len(dates_medium), len(dates_high))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a22fc6ac-1260-402e-8dda-558638c14b4e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# ## load the preprocessed mclimate comparison to AR dates at 72 hour lead\n",
    "# fname_pattern = path_to_data + 'preprocessed/mclimate_AR_dates/mclimate_ivt_*_F72.nc'\n",
    "# ds = xr.open_mfdataset(fname_pattern, engine='netcdf4', combine='nested', concat_dim=\"valid_time\")\n",
    "\n",
    "# data_lst = []\n",
    "# for i, dt_vals in enumerate(dates_lst):\n",
    "#     tmp = ds.sel(valid_time=dt_vals) # subset to high/medium/low impact dates\n",
    "#     # tmp = tmp.isel(valid_time=100)\n",
    "#     tmp = tmp.mean('valid_time') # average the composite\n",
    "#     data_lst.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f20bd608-7559-4f98-bded-411564f22db3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "must supply at least one object to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/SEAK-impacts/lib/python3.12/site-packages/xarray/core/concat.py:230\u001b[0m, in \u001b[0;36mconcat\u001b[0;34m(objs, dim, data_vars, coords, compat, positions, fill_value, join, combine_attrs)\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 230\u001b[0m     first_obj, objs \u001b[38;5;241m=\u001b[39m \u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpeek_at\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/SEAK-impacts/lib/python3.12/site-packages/xarray/core/utils.py:193\u001b[0m, in \u001b[0;36mpeek_at\u001b[0;34m(iterable)\u001b[0m\n\u001b[1;32m    192\u001b[0m gen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28miter\u001b[39m(iterable)\n\u001b[0;32m--> 193\u001b[0m peek \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m peek, itertools\u001b[38;5;241m.\u001b[39mchain([peek], gen)\n",
      "\u001b[0;31mStopIteration\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 28\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[1;32m     26\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m ds_final \u001b[38;5;241m=\u001b[39m \u001b[43mxr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mds_lst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimpact_dates\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m data \u001b[38;5;241m=\u001b[39m ds_final\u001b[38;5;241m.\u001b[39mmean(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimpact_dates\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     30\u001b[0m data_lst\u001b[38;5;241m.\u001b[39mappend(data)\n",
      "File \u001b[0;32m~/miniconda3/envs/SEAK-impacts/lib/python3.12/site-packages/xarray/core/concat.py:232\u001b[0m, in \u001b[0;36mconcat\u001b[0;34m(objs, dim, data_vars, coords, compat, positions, fill_value, join, combine_attrs)\u001b[0m\n\u001b[1;32m    230\u001b[0m     first_obj, objs \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mpeek_at(objs)\n\u001b[1;32m    231\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[0;32m--> 232\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmust supply at least one object to concatenate\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compat \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m _VALID_COMPAT:\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    236\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompat=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcompat\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m invalid: must be \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbroadcast_equals\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mequals\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124midentical\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mno_conflicts\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moverride\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    237\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: must supply at least one object to concatenate"
     ]
    }
   ],
   "source": [
    "data_lst = []\n",
    "for i, dt_vals in enumerate(dates_lst):\n",
    "    ## get string values for opening datasets\n",
    "    dates_new = []\n",
    "    mon_lst = []\n",
    "    day_lst = []\n",
    "    for i, date in enumerate(dt_vals):\n",
    "        # ts = pd.to_datetime(str(date))\n",
    "        ts = date\n",
    "        d = ts - timedelta(days=3)\n",
    "        t = d.strftime('%Y%m%d')\n",
    "        mon_lst.append(d.month)\n",
    "        day_lst.append(d.day)\n",
    "        dates_new.append(t)\n",
    "\n",
    "    ## now compare mclimate to each forecast\n",
    "    ds_lst = []\n",
    "    for j, dates in enumerate(dates_new):\n",
    "        try:\n",
    "            fc = mclim_func.load_reforecast(dates, 'ivt')\n",
    "            mclimate = mclim_func.load_mclimate(mon_lst[j], day_lst[j])\n",
    "            \n",
    "            ds = mclim_func.compare_mclimate_to_forecast(fc, mclimate)\n",
    "            ds_lst.append(ds)\n",
    "        except OSError:\n",
    "            pass\n",
    "    \n",
    "    ds_final = xr.concat(ds_lst, dim=\"impact_dates\")\n",
    "    data = ds_final.mean('impact_dates')\n",
    "    data_lst.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6ea008-68ae-467a-b490-23fa868456b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.nanmin(data_lst[1].ivt_mclimate.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61812abc-df4e-44cb-a0d9-4234bb9ce481",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lst[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b74a5b8-aad4-4667-a11c-15904745b49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up projection\n",
    "mapcrs = ccrs.Mercator()\n",
    "# mapcrs = ccrs.PlateCarree()\n",
    "datacrs = ccrs.PlateCarree()\n",
    "\n",
    "# Set tick/grid locations\n",
    "lats = data_lst[0].lat.values\n",
    "lons = data_lst[0].lon.values\n",
    "dx = np.arange(lons.min().round(),lons.max().round()+10,10)\n",
    "dy = np.arange(lats.min().round(),lats.max().round()+5,5)\n",
    "\n",
    "ext = [-170., -120., 40., 65.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5131d774-e472-44e5-8311-eef57bfe049e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create figure\n",
    "fig = plt.figure(figsize=(19, 5))\n",
    "fig.dpi = 300\n",
    "fname = path_to_figs + 'impact_NWS_composite_{0}'.format(zone)\n",
    "fmt = 'png'\n",
    "\n",
    "nrows = 1\n",
    "ncols = 4\n",
    "\n",
    "# contour labels\n",
    "kw_clabels = {'fontsize': 7, 'inline': True, 'inline_spacing': 7, 'fmt': '%i',\n",
    "              'rightside_up': True, 'use_clabeltext': True}\n",
    "\n",
    "kw_ticklabels = {'size': 10, 'color': 'dimgray', 'weight': 'light'}\n",
    "\n",
    "## Use gridspec to set up a plot with a series of subplots that is\n",
    "## n-rows by n-columns\n",
    "gs = GridSpec(nrows, ncols, height_ratios=[1], width_ratios = [1, 1, 1, 0.05], wspace=0.001, hspace=0.05)\n",
    "## use gs[rows index, columns index] to access grids\n",
    "\n",
    "###################\n",
    "### CLIMATOLOGY ###\n",
    "###################\n",
    "leftlats_lst = [True, False, False]\n",
    "lbl = ['Low Impact', 'Medium Impact', 'High Impact']\n",
    "for i, fc in enumerate(data_lst):\n",
    "    ax = fig.add_subplot(gs[0, i], projection=mapcrs) \n",
    "    ax = draw_basemap(ax, extent=ext, xticks=dx, yticks=dy, left_lats=leftlats_lst[i], right_lats=False, bottom_lons=True)\n",
    "    \n",
    "    # Contour Filled\n",
    "    data = fc.ivt_mclimate.values*100.\n",
    "    # cmap, norm, bnds = ccmap.cmap('mclimate_purple')\n",
    "    # cf = ax.contourf(fc.lon, fc.lat, data, transform=datacrs,\n",
    "    #                  levels=bnds, cmap=cmap, norm=norm, alpha=0.9, extend='neither')\n",
    "\n",
    "    cmap = cmo.deep\n",
    "    bnds = np.arange(75, 100.5, 0.5)\n",
    "    cf = ax.contourf(fc.lon.values, fc.lat.values, data, transform=datacrs,\n",
    "                     levels=bnds, cmap=cmap, alpha=0.9, extend='both')\n",
    "    ax.set_title(lbl[i], loc='left', fontsize=10)\n",
    "    \n",
    "    # # Contour Lines\n",
    "    # clevs = np.arange(250., 2100., 250.)\n",
    "    # cs = ax.contour(ds.lon, ds.lat, ds.IVT, transform=datacrs,\n",
    "    #                  levels=clevs, colors='k',\n",
    "    #                  linewidths=0.75, linestyles='solid')\n",
    "    # plt.clabel(cs, **kw_clabels)\n",
    "    \n",
    "    # ts = pd.to_datetime(str(ds.time.values)) \n",
    "    # init_time = ts.strftime('%HZ %d %b %Y')\n",
    "    # start_date = ts - timedelta(days=45)\n",
    "    # start_date = start_date.strftime('%d-%b')\n",
    "    # end_date = ts + timedelta(days=45)\n",
    "    # end_date = end_date.strftime('%d-%b')\n",
    "    \n",
    "    # ts = pd.to_datetime(str(ds.valid_time.values)) \n",
    "    # valid_time = ts.strftime('%HZ %d %b %Y')\n",
    "    \n",
    "    # ax.set_title('Model Run: {0}'.format(init_time), loc='left', fontsize=10)\n",
    "    # ax.set_title('Valid Date: {0}'.format(valid_time), loc='right', fontsize=10)\n",
    "\n",
    "    \n",
    "    # txt = 'Relative to all 162-h GEFSv12 reforecasts initialized between {0} and {1} (2000-2019)'.format(start_date, end_date)\n",
    "    # ann_ax = fig.add_subplot(gs[-1, i])\n",
    "    # ann_ax.axis('off')\n",
    "    # ann_ax.annotate(textwrap.fill(txt, 60), # this is the text\n",
    "    #            (0, 0.), # these are the coordinates to position the label\n",
    "    #             textcoords=\"offset points\", # how to position the text\n",
    "    #             xytext=(25,-35), # distance from text to points (x,y)\n",
    "    #             ha='left', # horizontal alignment can be left, right or center\n",
    "    #             **kw_ticklabels)\n",
    "\n",
    "\n",
    "# Add color bar\n",
    "cbax = plt.subplot(gs[0,-1]) # colorbar axis\n",
    "cb = Colorbar(ax = cbax, mappable = cf, orientation = 'vertical', ticklocation = 'right')\n",
    "cb.set_label('Model Climate Percentile Rank (xth)', fontsize=10)\n",
    "cb.ax.tick_params(labelsize=8)\n",
    "\n",
    "fig.savefig('%s.%s' %(fname, fmt), bbox_inches='tight', dpi=fig.dpi)\n",
    "\n",
    "# Show\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec4e4a0-12c0-477a-9d9b-5f92b003927f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (SEAK-impacts)",
   "language": "python",
   "name": "seak-impacts"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

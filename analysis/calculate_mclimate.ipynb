{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa95c261-0095-455b-babc-acd6209ce4bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<dask.config.set at 0x2ad0109361d0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## import libraries\n",
    "import os, sys\n",
    "import yaml\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import metpy.calc as mpcalc\n",
    "from metpy.units import units\n",
    "import dask\n",
    "from datetime import timedelta\n",
    "%matplotlib inline\n",
    "\n",
    "sys.path.append('../modules')\n",
    "import ar_funcs\n",
    "dask.config.set(**{'array.slicing.split_large_chunks': True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4d78ade-4b91-4aab-b542-3f8e27b4c7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = '/cw3e/mead/projects/cwp140/scratch/dnash/data/'      # project data -- read only\n",
    "path_to_out  = '../out/'       # output files (numerical results, intermediate datafiles) -- read & write\n",
    "path_to_figs = '../figs/'      # figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96cc7f58-a892-43b1-a3b8-3d86c42178e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filename_GEFSv12_reforecast(F):\n",
    "    ## this is the number of hours of lead time\n",
    "    ## for getting the correct filename\n",
    "    \n",
    "    # F = int((np.timedelta64(ndays, 'D')+np.timedelta64(nhours, 'h'))/np.timedelta64(1, 'h'))\n",
    "    ## the F-lead that the files are saved as\n",
    "    li = [3, 24, 27, 48, 51, 72, 75, 96, 99, 120, 123, 144, 147, 168, 171, 192, 195, 216, 219, 240]\n",
    "    \n",
    "    for idx in range(len(li)-1):\n",
    "        if li[idx] < F <= li[idx+1]:\n",
    "            pos1, pos2 = idx, idx+1\n",
    "\n",
    "    return li[pos1], li[pos2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e53282b4-173d-4fe4-a8a0-f4adf7c0eb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 24 hour lead from Nov 21, 2023 00 UTC\n",
    "F = 24\n",
    "mon = 11\n",
    "day = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d62b7ce5-3792-4abc-a92c-4abe8fd3aedc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-09-30 00:00:00 2019-12-29 00:00:00\n",
      "Gathering filenames ...\n",
      "Reading the data ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR 1: PROJ: proj_create_from_database: Open of /cw3e/mead/projects/cwp140/scratch/dnash/miniconda3/envs/SEAK-impacts/share/proj failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating quantiles...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "lengths of dim and axis should be identical.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:71\u001b[0m\n",
      "File \u001b[0;32m/cw3e/mead/projects/cwp140/scratch/dnash/miniconda3/envs/SEAK-impacts/lib/python3.11/site-packages/xarray/core/dataset.py:4240\u001b[0m, in \u001b[0;36mDataset.expand_dims\u001b[0;34m(self, dim, axis, **dim_kwargs)\u001b[0m\n\u001b[1;32m   4237\u001b[0m     axis \u001b[38;5;241m=\u001b[39m [axis]\n\u001b[1;32m   4239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(dim) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(axis):\n\u001b[0;32m-> 4240\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlengths of dim and axis should be identical.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   4241\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m dim:\n\u001b[1;32m   4242\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdims:\n",
      "\u001b[0;31mValueError\u001b[0m: lengths of dim and axis should be identical."
     ]
    }
   ],
   "source": [
    "%%time\n",
    "F = 162\n",
    "mon = 11\n",
    "day = 14\n",
    "\n",
    "## for each year between 2000 and 2019\n",
    "date_lst = []\n",
    "for i, yr in enumerate(range(2000, 2020)):\n",
    "    ## get 45 days before date\n",
    "    center_date = '{0}-{1}-{2}'.format(yr, mon, day)\n",
    "    center_date = pd.to_datetime(center_date)\n",
    "    start_date = center_date - timedelta(days=45)\n",
    "    \n",
    "    ## get 45 days after November 21\n",
    "    end_date = center_date + timedelta(days=45)\n",
    "\n",
    "    ## make a list of dates between start_date and end_date\n",
    "    dates = pd.date_range(start_date, end_date, freq='1D')\n",
    "    \n",
    "    date_lst.append(dates)\n",
    "    \n",
    "## concatenate all years together into single list    \n",
    "final_lst = np.concatenate(date_lst)\n",
    "print(start_date, end_date)\n",
    "\n",
    "## load all days from the new subset\n",
    "## create list of fnames\n",
    "fname_lst = []\n",
    "path_to_data = '/data/projects/Comet/cwp140/'\n",
    "path_to_data = '/cw3e/mead/projects/cwp140/scratch/dnash/data/'\n",
    "varname = 'ivt'\n",
    "\n",
    "## append filenames to a list\n",
    "print('Gathering filenames ...')\n",
    "for i, dt in enumerate(final_lst):\n",
    "    ts = pd.to_datetime(str(dt)) \n",
    "    d = ts.strftime(\"%Y%m%d\")\n",
    "    F1, F2 = get_filename_GEFSv12_reforecast(F)\n",
    "    fname = path_to_data + 'preprocessed/GEFSv12_reforecast/{0}/{1}_{0}_F{2}_F{3}.nc'.format(varname, d, F1, F2)\n",
    "    fname_lst.append(fname)\n",
    "\n",
    "### Read the dataset\n",
    "print('Reading the data ...')\n",
    "### Select the xx hr lead time step\n",
    "## this is the index value for selecting the timestep in the dataset\n",
    "idx = np.timedelta64(int(np.timedelta64(F, 'h')/np.timedelta64(1, 'ns')), 'ns')\n",
    "\n",
    "def preprocess(ds):\n",
    "    ds = ds.drop_vars([\"ivtu\", \"ivtv\"])\n",
    "    ds = ds.sel(step=idx) # select the 24 hr lead step\n",
    "    \n",
    "    return ds\n",
    "\n",
    "## use xr.open_mfdataset to read all the files within that ssn clim\n",
    "ds = xr.open_mfdataset(fname_lst, concat_dim=\"valid_time\", combine=\"nested\", engine='netcdf4', chunks={\"lat\": 100, \"lon\": 100}, preprocess=preprocess)\n",
    "\n",
    "print('Calculating quantiles...')\n",
    "## need to rechunk so time is a single chunk\n",
    "ds = ds.chunk(dict(valid_time=-1))\n",
    "\n",
    "# Percentile will be a set range of percentiles including <90th, then every 0.1 until 100th/MAX\n",
    "# I might add 75th-90th, and < 75th\n",
    "a = np.array([0, .75, .9])\n",
    "b = np.arange(.91, 1.001, 0.01)\n",
    "quantile_arr = np.concatenate((a, b), axis=0)\n",
    "\n",
    "## Calculate the percentiles\n",
    "ivt_mclimate = ds.quantile(quantile_arr, dim=['valid_time', 'number'], skipna=True)\n",
    "\n",
    "## add dayofyear and lead to coordinates\n",
    "ivt_mclimate = ivt_mclimate.assign_coords(step=F)\n",
    "ivt_mclimate = ivt_mclimate.expand_dims('step')\n",
    "period = pd.Period(\"2023-{0}-{1}\".format(mon, day), freq='H')\n",
    "ivt_mclimate = ivt_mclimate.assign_coords(dayofyear=period.day_of_year)\n",
    "ivt_mclimate = ivt_mclimate.expand_dims('dayofyear')\n",
    "ivt_mclimate\n",
    "\n",
    "# write to netCDF\n",
    "fname = os.path.join(path_to_data, 'preprocessed/GEFSv12_reforecast_mclimate_ivt_{0}{1}_{2}hr-lead.nc'.format(mon, day, F))\n",
    "ivt_mclimate.load().to_netcdf(path=fname, mode = 'w', format='NETCDF4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922ce3af-a397-4c63-b7e7-616f050f4c81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (SEAK-impacts)",
   "language": "python",
   "name": "seak-impacts"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
